---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# mfair: Matrix Factorization with Auxiliary Information in R

<!-- badges: start -->
<!-- badges: end -->

Methods for matrix factorization to leverage auxiliary information based on the paper MFAI.
The name of the package `mfair` comes from **Matrix Factorization with Auxiliary Information in R**.

## Installation

You can install the development version of `mfair` from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("YangLabHKUST/mfair")
```

## Example

This is a basic example which shows you how to solve a common problem:

```{r example1}
set.seed(20230306)
library(mfair)
library(MASS)

# Simulate data
# Set the data dimension and rank
N <- 100
M <- 100
K_true <- 2L

# Set the proportion of variance explained (PVE)
PVE_Z <- 0.8
PVE_Y <- 0.5

# Generate auxiliary information X
X1 <- runif(N, min = -10, max = 10)
X2 <- runif(N, min = -10, max = 10)
X <- cbind(X1, X2)

# F(X)
FX1 <- X1 / 2 - X2
FX2 <- (X1^2 - X2^2 + 2 * X1 * X2) / 10
FX <- cbind(FX1, FX2)

# Generate loadings
beta1 <- var(FX1) * (1 / PVE_Z - 1)
Z1 <- mvrnorm(n = 1, mu = FX1, Sigma = beta1 * diag(N))
beta2 <- var(FX2) * (1 / PVE_Z - 1)
Z2 <- mvrnorm(n = 1, mu = FX2, Sigma = beta2 * diag(N))
Z <- cbind(Z1, Z2)

# Generate factors
W <- matrix(rnorm(M * K_true), nrow = M, ncol = K_true)

# Generate the main data matrix Y
Y <- Z %*% t(W)
Y_var <- var(as.vector(Y))
epsilon <- sqrt(Y_var * (1 / PVE_Y - 1))
Y_obs <- Y + matrix(rnorm(N * M, sd = epsilon), nrow = N, ncol = M)
Y_mean <- mean(Y_obs)

# Create MFAIR object
mfairObject <- createMFAIR(Y_obs - Y_mean, X, K_max = K_true)

# Fit the MFAI model
mfairObject <- fitGreedy(mfairObject, verbose_loop = FALSE)

# Prediction based on the low-rank approximation
Y_hat <- predict(mfairObject) + Y_mean

# Root-mean-square-error
rmse <- sqrt(mean((Y_obs - Y_hat)^2))
rmse
```

`mfair` can also handle the matrix with missing entries:
```{r example2}
# Split the data into the training set and test set
n_all <- N * M
training_ratio <- 0.5
train_set <- sample(1:n_all, n_all * training_ratio, replace = FALSE)
Y_train <- Y_test <- Y_obs
Y_train[-train_set] <- NA
Y_test[train_set] <- NA
train_mean <- mean(Y_train, na.rm = TRUE)

# Create MFAIR object
mfairObject <- createMFAIR(Y_train - train_mean, X, K_max = K_true)

# Fit the MFAI model
mfairObject <- fitGreedy(mfairObject, verbose_loop = FALSE)

# Prediction based on the low-rank approximation
Y_hat <- predict(mfairObject) + train_mean

# Root-mean-square-error
rmse <- sqrt(mean((Y_test - Y_hat)^2, na.rm = TRUE))
rmse
```


## Development

The package is developed by Zhiwei Wang (<zhiwei.wang@connect.ust.hk>).

## Contact Information

Please feel free to contact Zhiwei Wang (<zhiwei.wang@connect.ust.hk>), Prof. Mingxuan Cai (<mingxcai@cityu.edu.hk>), or Prof. Can Yang (<macyang@ust.hk>) with any inquiries.
